{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d2897",
   "metadata": {},
   "source": [
    "# Transformer Text Generation\n",
    "\n",
    "In this notebook, we will explore how transformer models (like GPT-2) can generate text based on a given prompt. We will experiment with generating text by adjusting parameters like temperature and sequence length.\n",
    "\n",
    "## Instructions\n",
    "1. Change the prompt below to experiment with different types of text generation.\n",
    "2. Adjust the `max_length` and `temperature` parameters to see how they affect the output.\n",
    "3. Generate at least 3 samples with different prompts and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbce095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielburnayev/Desktop/Cognizant GenAI/ai_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'COMMAND_MODE': 'unix2003', 'CONDA_DEFAULT_ENV': 'base', 'CONDA_EXE': '/opt/miniconda3/bin/conda', 'CONDA_PREFIX': '/opt/miniconda3', 'CONDA_PROMPT_MODIFIER': '(base) ', 'CONDA_PYTHON_EXE': '/opt/miniconda3/bin/python', 'CONDA_SHLVL': '1', 'HOME': '/Users/danielburnayev', 'HOMEBREW_CELLAR': '/opt/homebrew/Cellar', 'HOMEBREW_PREFIX': '/opt/homebrew', 'HOMEBREW_REPOSITORY': '/opt/homebrew', 'INFOPATH': '/opt/homebrew/share/info:', 'LOGNAME': 'danielburnayev', 'MallocNanoZone': '0', 'OLDPWD': '/', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'PATH': '/Users/danielburnayev/Desktop/Cognizant GenAI/ai_venv/bin:/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.10/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/usr/local/MacGPG2/bin:/Applications/Wireshark.app/Contents/MacOS:/Users/danielburnayev/flutter/bin', 'PWD': '/', 'SHELL': '/bin/zsh', 'SHLVL': '1', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.mQ4mwpQB4B/Listeners', 'TMPDIR': '/var/folders/rd/q731sk811f77v0tsznmn6lfc0000gn/T/', 'USER': 'danielburnayev', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_CODE_CACHE_PATH': '/Users/danielburnayev/Library/Application Support/Code/CachedData/6c3e3dba23e8fadc360aed75ce363ba185c49794', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'VSCODE_CWD': '/', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_IPC_HOOK': '/Users/danielburnayev/Library/Application Support/Code/1.81-main.sock', 'VSCODE_NLS_CONFIG': '{\"locale\":\"en-us\",\"osLocale\":\"en-us\",\"availableLanguages\":{},\"_languagePackSupport\":true}', 'VSCODE_PID': '30627', 'XPC_FLAGS': '0x0', 'XPC_SERVICE_NAME': '0', '_': '/Users/danielburnayev/Desktop/Cognizant GenAI/ai_venv/bin/python', '__CFBundleIdentifier': 'com.microsoft.VSCode', '__CF_USER_TEXT_ENCODING': '0x1F5:0x0:0x0', 'ELECTRON_RUN_AS_NODE': '1', 'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL': '1', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'utf-8', 'VIRTUAL_ENV': '/Users/danielburnayev/Desktop/Cognizant GenAI/ai_venv', 'PS1': '(ai_venv) ', 'VIRTUAL_ENV_PROMPT': '(ai_venv) ', 'LC_CTYPE': 'UTF-8', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the future, education will not be the focus of daily life.\n",
      "\n",
      "But the issue is one that needs to be addressed.\n",
      "\n",
      "\"There is a tremendous number of students who are looking for a way to get into college,\" said Gary Bostock, a junior from Lakewood, Ill. \"They want to get into a program that has a high-quality education and they want to build a career in the business world.\"\n",
      "\n",
      "Bostock and his peers have been asking for a \"College Without Bars\" program that would allow students to attend college without an early retirement.\n",
      "\n",
      "The plan would require every person who attends college to have an ID card.\n",
      "\n",
      "In other words, in a world where people can't go to college now, many have to wait until they can start their own businesses.\n",
      "\n",
      "\"We are looking at a system that will be in place,\" Bostock said.\n",
      "\n",
      "This is not a new idea.\n",
      "\n",
      "In the 1960s, the U.S. Department of Education had plans to provide free college lunches to all students in low-income communities.\n",
      "\n",
      "But after a federal judge in 1979 ruled that that program was unconstitutional, the government moved the first step toward giving students free lunch.\n",
      "\n",
      "The idea was to\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load GPT-2 text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Set your prompt\n",
    "prompt = 'In the future, education will'\n",
    "\n",
    "# Generate text\n",
    "result = generator(prompt, max_length=50, temperature=0.7)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69a033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The impact of AI on the future of work has been a major driver of rising productivity, productivity increases and productivity declines for nearly 15 years,\" said Tanya Vaidal, chief technology officer at the National Bureau of Economic Research.\n",
      "\n",
      "It's a \"sustainability crisis\" that must be addressed\n",
      "\n",
      "In 2009, a report by the Organization of American States, OECD and the International Monetary Fund found that the United States could be headed for a recession by 2035, with the world's biggest economy, the US, expected to be hit by around 3 percent growth by 2035.\n",
      "\n",
      "The report also cited the high productivity that human-made technologies can bring.\n",
      "\n",
      "The report concluded that the US was the fastest growing economy in Europe and Asia and an OECD member country with an \"extremely high percentage of young people achieving a degree of autonomy.\"\n",
      "\n",
      "The report said that the rate of innovation in the United States could be as high as 30 percent.\n",
      "\n",
      "It also found an \"unprecedented and unprecedented productivity growth for the United States over the last decade that reflects a growing sense of technological opportunity\" and a \"challenging need for increased productivity\" in the United States.\n",
      "\n",
      "It also said that the United States was one of the only economies in the world that has a high percentage\n",
      "---------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a kingdom of dragons; this kingdom had been conquered by a dragon, a dragon that killed all the dragons and set them free. In the end, the dragon king, who had been the first to ever destroy a dragon, would be the one to destroy it all.\n",
      "\n",
      "The Dragon King\n",
      "\n",
      "A dragon was a great king who had been the first to conquer a kingdom. He was the first king of a kingdom and he had been the first to actually destroy the dragons.\n",
      "\n",
      "The Dragon King is the most powerful dragon in the world, and he was the first to actually destroy the dragon.\n",
      "\n",
      "The Dragon King is the king of a kingdom and he had been the first to actually destroy the dragon.\n",
      "\n",
      "The Dragon King was the first to actually destroy the dragon.\n",
      "\n",
      "The Dragon King was the king of a kingdom and he had been the first to actually destroy the dragon.\n",
      "\n",
      "The Dragon King was the king of a kingdom and he had been the first to actually destroy the dragon.\n",
      "\n",
      "The Dragon King was the king of a kingdom and he had been the first to actually destroy the dragon.\n",
      "\n",
      "The Dragon King was the king of a kingdom and he had been the first to actually destroy the dragon.\n",
      "\n",
      "The Dragon King was the\n",
      "---------------------------------------------------------------------\n",
      "In the future, education will become an issue that politicians will decide on. The government also is considering a scheme to create a new academic system that will allow students to study in the humanities.\n",
      "\n",
      "\"If they want to be able to study in the humanities, I think that would be an ideal place,\" he said.\n",
      "\n",
      "The government has already announced that the next generation of teachers would be required to attend a master's degree from a government institution, with the goal of taking those students to higher education.\n",
      "\n",
      "\"I think it's very important that there's a strong program of course-based education and it's not going to be just a one-size fits and starts, but rather, a whole learning process and that's something that we had to start with in the past,\" said Mr. Cottrell.\n",
      "\n",
      "He said there are reasons to believe that the government has a plan in place to help new teachers.\n",
      "\n",
      "\"The government's thinking about it is that it's a step in the right direction. It's a step forward and it's a step backward,\" he said.\n",
      "\n",
      "With files from CTV Toronto\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different prompts\n",
    "prompt = 'The impact of AI on the future of work'\n",
    "result = generator(prompt, max_length=50, temperature=0.8)\n",
    "print(result[0]['generated_text'])\n",
    "\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "prompt = 'Once upon a time, there was a kingdom'\n",
    "result = generator(prompt, max_length=100, temperature=0.6)\n",
    "print(result[0]['generated_text'])\n",
    "\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "#same test again\n",
    "prompt = 'In the future, education will'\n",
    "result = generator(prompt, max_length=50, temperature=0.7)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d0d32",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Now that you have experimented with text generation, write a brief report on your observations.\n",
    "\n",
    "1. What patterns did you notice in the generated text?\n",
    "2. How did changing the temperature affect the creativity and coherence of the text?\n",
    "3. What types of prompts yielded the most coherent results?\n",
    "4. What are the limitations of GPT-2 based on your experimentation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
